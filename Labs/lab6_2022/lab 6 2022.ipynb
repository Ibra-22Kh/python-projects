{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Objectives\n",
    "- Learn how to build a classifier to recognize hand written digits\n",
    " - Class encoding (One hot encoding)\n",
    " - Softmax activation function\n",
    "- Learn how to use dropout layers to improve generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten Digits Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will build a network that can recognize handwritten numbers. For achieving this\n",
    "goal, we use MNIST (for more information, refer to http://yann.lecun.com/exdb/mnist/), a database of\n",
    "handwritten digits made up of a training set of 60,000 examples and a test set of 10,000 examples.\n",
    "The training examples are annotated by humans with the correct answer. For instance, if the\n",
    "handwritten digit is the number three, then three is simply the label associated with that example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each MNIST image is in gray scale, and it consists of 28 x 28 pixels. A subset of these numbers is\n",
    "represented in the following diagram:\n",
    "\n",
    "\n",
    "![dataset](subset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax activation function\n",
    "\n",
    "How does a softmax function work?\n",
    "\n",
    "The softmax function squashes the outputs of each unit to be between 0 and 1, just like a sigmoid function. But it also divides each output such that the total sum of the outputs is equal to 1 (check it on the figure below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![softmax_exp](softmax_exp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the softmax function is equivalent to a categorical probability distribution, it tells you the probability that any of the classes are true.\n",
    "\n",
    "Mathematically the softmax function is shown below, where z is a vector of the inputs to the output layer (if you have 10 output units, then there are 10 elements in z). And again, j indexes the output units, so j = 1, 2, ..., K.\n",
    "\n",
    "The softmax function\n",
    "![softmax](softmax.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Input, Activation\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibility\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('DATASET/X_train.npy')\n",
    "y_train = np.load('DATASET/y_train.npy')\n",
    "X_test = np.load('DATASET/X_test.npy')\n",
    "y_test = np.load('DATASET/y_test.npy')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#OR run this:\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?\n",
    "# reshape\n",
    "# normalize\n",
    "# convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Simple net (Single Layer NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple network (without hidden layers), name it model\n",
    "# train it with sgd optimizer for 200 epoch and 128 batch size\n",
    "# use validation_split parameter for fit function with the value 0.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the simple net with hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network with two hidden layers (128 neuron in each) and 'relu' activation function, name it model_2\n",
    "# train it with sgd optimizer for 20 epoch and 128 batch size\n",
    "# use validation_split parameter for fit function with the value 0.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2 = model_2.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test score:\", score_2[0])\n",
    "print('Test accuracy:', score_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further improving with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network with two hidden layers (128 neuron in each) and 'relu' activation function, name it model_3\n",
    "# add Dropout with 0.3 after each hidden layer\n",
    "# train it with sgd optimizer for 20 epoch and 128 batch size\n",
    "# use validation_split parameter for fit function with the value 0.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate the prevoius net but train it for 250 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_3.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
